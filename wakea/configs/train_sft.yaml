seed: 1337
batch_size: 4
lr: 3.0e-4
max_steps: 10
use_rfs: false

data:
  path: wakea/data/schemas/sft_dialogue.jsonl
  tokenizer: null  # e.g., 'gpt2' if transformers installed
  max_len: 256

model_cfg: wakea/configs/model.yaml
output_dir: checkpoints/sft
tool_cfg: wakea/configs/tools.yaml
tool_loss_weight: 0.2
tool_data:
  path: wakea/data/schemas/tool_use.jsonl
  tokenizer: null
  max_len: 256
